{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "The data test results from all Qld Health facilities.\n",
    "\n",
    "This includes some community centres but not all.\n",
    "\n",
    "As of  <span style=\"color:red\">**4th June 2020**</span> in Queensland there were:\n",
    "\n",
    "| | Queensland | Dataset| % Represented| \n",
    "|--|--|--|--|\n",
    "|**Tests**|208 758|103 983|49.8%| \n",
    "|**Cases**|1 060|943|88.96%| \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Overall structure of files:\n",
    "\n",
    "\n",
    "|Lab_No | Test_Code | Test_Description | Date_Collected |Time_collected |Sex |Age | Category_Code| Facility_Code |Facility_Description |Result |Result_Comment |\n",
    "|--|-|-|-|-|- |-|-|-|-|-|-|\n",
    "|Lab number generated for **each sample** taken.<br><br> Multiple tests can be run on the same lab number.| One of for available tests (see below) | Describes the test. | Date sample was collected |Time sample was collected |Patient sex |Patient age |For Medicare billing; not used in present study. |Facility code where the test was ordered from |Full faclity name |Result |Comment on result. These vary panding on stage of pandemic (see below on how this was handled)|\n",
    "\n",
    "\n",
    "\n",
    "**TEST CODES**\n",
    "\n",
    "'NCVPCR' = Screening code; if detected a confirmation test will be ordered under the same laboratory number (3rd Gen)\n",
    "\n",
    "'CRTAQ' = Confirmatory test for NCVPCR; OR a screening test if NCVPCR or CRPCR havent been done (2nd Gen)\n",
    "\n",
    "'CRPCR' = Screening code; if detected a confirmation test will be ordered under the same laboratory number (2nd Gen)\n",
    "\n",
    "'CORPCR' = Older test (1st Gen)\n",
    "\n",
    "'XPNCV' = Screening code; if detected a confirmation test will be ordered under the same laboratory number (4th Gen)\n",
    "\n",
    "\n",
    "CRPCR and CRTAQ are FSS codes - if detected in any of these tests then it is assumed that virus particules have been detected\n",
    "\n",
    "\n",
    "\n",
    "******************\n",
    "\n",
    "## Wrangling Process\n",
    "\n",
    "Over all aim is to have 1 test result per patient per day.\n",
    "\n",
    "1. STEP 1: DEAL WITH NULL/MISSING VALUES or WRONG FORMAT VALUES\n",
    "    - Missing age and sex values categorised as \"Not reported\".\n",
    "    - Drop missing date collected.\n",
    "    - Put ages into age bracket based on ABS.\n",
    "    \n",
    "    \n",
    "2. STEP 2: CONVERT TO DATE TIME TO DATETIME FORMAT\n",
    "    - This includes adding a \"DateTime collected\" column based on Date collected and Time collected columns\n",
    "   \n",
    "\n",
    "3. STEP 3: DETERMINE WHETHER EACH ROW IS A POISITIVE OR NEGATIVE TEST\n",
    "    - 'Not Detected' = NO \n",
    "    - 'DETECTED' = YES \n",
    "    -  nan = depending on Results_comment\n",
    "        -As definied by clinicians:\n",
    "            'This test is currently under evaluation and has not been fully validated.' = **NOT DETECTED** = NO\n",
    "            'F' = **NOT DETECTED** = NO\n",
    "            'Not Detected' = **NOT DETECTED** = NO\n",
    "            'This assay is still undergoing development and is not yet fully validated. Results should be interpreted in association with all other information (clinical and laboratory) on the patient. Reports based on this assay are not currently NATA/RCPA endorsed. This test is currently under evaluation and has not been fully validated.' = **NOT DETECTED** = NO\n",
    "            'Sample referred for confirmatory testing.~This test is currently under evaluation and has not been fully validated.'] = **DETECTED** = YES\n",
    "            'np.nan' = **NOT DETECTED** = NO\n",
    "    - 'See Comment' or 'See comment' = Some of the comments indicate that that the virus is not detected whereas other commends indicate that it is. Overall logic will be to:\n",
    "        - Identify rows where it explicitly says that the virus is NOT detected and change this to \"NO\"\n",
    "        - Identify rows where it explicitly says that the virus IS detected and change this to \"YES\"\n",
    "        - Identify rows where there is a NaN and change this to \"NO\"\n",
    "        - Where the test has been \"referred\" - will assume that virus HAS BEEN detected and change this to \"YES\"\n",
    "        \n",
    "\n",
    "4. STEP 4: DETERMINE WHETHER EACH LAB_NO IS A POISITIVE OR NEGATIVE TEST\n",
    "    - There are several Lab_No's that have duplicate values.\n",
    "    - Overall logic\n",
    "        - If the lab results are the **SAME** for the same lab_no then drop the duplciate and keep one result only\n",
    "        - If the lab results are **DIFFERENT** for the same lab_no, then manual validation by clinician/pathology was required do to variation decision making.\n",
    "  \n",
    "\n",
    "5. STEP 5: REMOVE DUPLICATE RESULTS ON THE SAME DAY\n",
    "    - i.e. Different Lab_No on the same day.\n",
    "    - As per clinician advice:\n",
    "        - If same results, then keep one copy only\n",
    "        - If there is a YES and NO result; keep YES\n",
    "        \n",
    "        \n",
    "6. STEP 6: CREATE FINAL DATAFRAME\n",
    "    - Remove unneeded columns\n",
    "    - Add new columns:\n",
    "        - Number of days since first test\n",
    "        - Number of days since first positive test\n",
    "        - Clinical status patient based on results\n",
    "            - Only one positive test required for a POS status\n",
    "            - Two negative tests >= 24 hours apart for a NEG status\n",
    "            - Remove multiple final negative status as these are redunat (ie: once negative and they dont switch back to positive but continue having a negative status)\n",
    "        - Flag days on which there is a status changes\n",
    "            - 1 == from positive to negative status\n",
    "            - 2 == from negative *back* to positive\n",
    "        - Time (days) to negative status \n",
    "            - CLINICALLY = clinical negativity is achieved on the *second* of the two negative tests;\n",
    "            - BIOLOGICALLY = biological negativity is achieved on the *first* of the two negative tests where the second test is considered to be a confirmation of the biological status;\n",
    "            - These were both counted twice for a **primaary** and **sensitivity** analysis\n",
    "                - PRIMARY analyis = patients are censored after they *first* achieve negative status\n",
    "                - SENSITIVITY analysis (\\_sensiv) = patients are followed until the end of their data\n",
    "                    - If a final negative is achieved then the patient is censored after the first first of the two dates (as above)\n",
    "                    - if a final negative is not achieved, then the patient is not censored\n",
    "                    - additional sensitivity analysis done on those that achieve a negative status only; where negative status is achieved by either:\n",
    "                        - Two neg tests: neg status will be counted as being achieved on the first of these two tests; OR\n",
    "                        - A final negative tests were no additional data is provided\n",
    "        - Max number of days since and including first positive test\n",
    "        - Max number of days before first positive test\n",
    "        - Number of total tests conducted\n",
    "        - Number of tests since and including first positive\n",
    "        - Number of times results changed from postive to negative until negative status is achieved for both primary and sensitivity analysis\n",
    "        - Number of POSITIVE tests since and including first positive\n",
    "        - Number of NEGATIVE tests since and including first positive\n",
    "        - Postcode of first test\n",
    "        - Facility name of first test\n",
    "        - Remoteness of first test\n",
    "    - Save final df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data file\n",
    "df = pd.read_csv(\"Outputs/MatchedDeidentified/MatchedDeidentifiedData.csv\")\n",
    "\n",
    "#get the ses and postcode file\n",
    "df_ses = pd.read_csv(\"Outputs/WrangledData/FacilityPostCodeAreaPopulation.csv\") \n",
    "\n",
    "df_ses = df_ses[[\"Facility_Description\",\n",
    "                # Address,\n",
    "                 \"PostCode\",\n",
    "                 \"Area\"\n",
    "                ]]\n",
    "\n",
    "\n",
    "#manually validated Lab_nos - i.e. those with multiple results per lab-No\n",
    "\n",
    "df_manual = pd.read_excel(\"Outputs/ForValidation/ForClinicianValidation_Validated.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n",
    "display(df.tail())\n",
    "\n",
    "\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n",
    "\n",
    "display(df_ses.head())\n",
    "\n",
    "\n",
    "print(\"\\n********************************************************************************\\n\")\n",
    "\n",
    "\n",
    "display(df_manual.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "print(len(df[\"Lab_No\"].unique()))\n",
    "\n",
    "print(len(df[\"Patient_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the unique values\n",
    "\n",
    "cols = list(df.columns)\n",
    "\n",
    "cols = [\"Test_Code\",\n",
    "        \"Category_Code\",\n",
    "       \"Facility_Code\",\n",
    "        \"Facility_Description\",\n",
    "       \"Sex\",\n",
    "       \"Result\"]\n",
    "\n",
    "for i in cols:\n",
    "    \n",
    "    print(i)\n",
    "    print(df[i].unique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Facility_Code\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the index a name\n",
    "df = df.set_index(\"ID\")\n",
    "\n",
    "#set Patient_ID as a factor\n",
    "\n",
    "df[\"Patient_ID\"] = df[\"Patient_ID\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_ses, on='Facility_Description', how='left')\n",
    "\n",
    "\n",
    "print(len(df[\"Patient_ID\"].unique()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************\n",
    "\n",
    "# <span style=\"color:magenta\"> **STEP 1: DEAL WITH NULL or WRONG FORMAT VALUES**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which columns are null\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************\n",
    "\n",
    "### <span style=\"color:magenta\">DEALING WITH DATE COLLECTED</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find rows that have a date\n",
    "\n",
    "pattern1 = r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\"\n",
    "\n",
    "detected = df[~df.Date_Collected.str.contains(pattern1)]\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "\n",
    "print(list(detected.Lab_No))\n",
    "\n",
    "print(detected.shape)\n",
    "\n",
    "detected.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(detected) > 10:\n",
    "    \n",
    "    print(\"TOO MANY MISSING VALUES removed!!!!\")\n",
    "    sys.exit()\n",
    "    \n",
    "else:\n",
    "    #drop these from df\n",
    "    df = df.drop(detected.index.values)\n",
    "    \n",
    "    print(len(detected), \" missing dates removed\")\n",
    "\n",
    "\n",
    "\n",
    "len(df.Lab_No.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************\n",
    "\n",
    "### <span style=\"color:magenta\">DEALING WITH AGE</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put a dummy number in so we can convert to int for imputation\n",
    "df[\"Age\"] = df[\"Age\"].fillna(-5)\n",
    "\n",
    "#convert to int\n",
    "df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "\n",
    "print(len(df[\"Lab_No\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put ages into bins < 65 , and 65 and over\n",
    "\n",
    "#create bins\n",
    "bins = np.arange(-5, 86, 5).tolist()\n",
    "#bins.append(120)\n",
    "\n",
    "bins = [-5,\n",
    "        0, \n",
    "        17,\n",
    "        65, \n",
    "        200]\n",
    "\n",
    "\n",
    "#create labels\n",
    "labels=  [\"Not reported\", \"16 and under\", \"17 to 64\", \"65 and over\"]\n",
    "\n",
    "print(labels)\n",
    "\n",
    "print(bins)\n",
    "\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "#df[df[\"Age\"]== -5 ][[\"Age\", \"AgeGroup\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[df[\"AgeGroup\"] == \"Not reported\"]), \" missing age categorised as 'not reported'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************\n",
    "\n",
    "### <span style=\"color:magenta\">DEALING WITH SEX</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put a value in for missing sex\n",
    "df[\"Sex\"] = df[\"Sex\"].fillna(\"Not reported\")\n",
    "\n",
    "\n",
    "print(len(df[df[\"Sex\"] == \"Not reported\"]), ' missing sex values coded as \"not reported\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:magenta\">**STEP 2: Deal with Date and Time Collected** <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 0 at front of time\n",
    "\n",
    "df[\"Time_collected\"] = df[\"Time_collected\"].str.lstrip()\n",
    "\n",
    "df[\"Time_collected\"] = df['Time_collected'].apply(lambda x: x.zfill(8))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a datetime column\n",
    "df['DateTime_Collected'] = df['Date_Collected'].str.cat(df['Time_collected'],sep=\" \")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date columns to datetime\n",
    "df[\"DateTime_Collected\"] = pd.to_datetime(df[\"DateTime_Collected\"], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "df[\"Date_Collected\"] = pd.to_datetime(df[\"Date_Collected\"], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first date of data\n",
    "print(\"FIRST DATE OF DATA:\")\n",
    "print(df[\"DateTime_Collected\"].min())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"LAST DATE OF DATA:\")\n",
    "print(df[\"DateTime_Collected\"].max())\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"DAYS OF DATA\")\n",
    "print(\"Number of days with data: \", len(df[\"Date_Collected\"].unique()))\n",
    "\n",
    "print(\"Number of days between first and last test in dataset: \", (df[\"DateTime_Collected\"].max() - df[\"DateTime_Collected\"].min()).days)\n",
    "\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:magenta\"> **STEP 3: CHANGE EACH _ROW_ TO BE DETECTED: YES or NO** <span>\n",
    "Change codes for detected/not detected to yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column called RESTUL_1.\n",
    "\n",
    "#If result = DETECTED then RESULT_1 is YES, otherwise put NAN\n",
    "df['Result_1'] = np.where(df['Result'] == 'DETECTED', \"YES\", np.nan)\n",
    "\n",
    "#If result = Not Detected then RESULT_1 is NO otherwise do nothing.\n",
    "df['Result_1'] = np.where(df['Result'] == 'Not Detected', \"NO\", df['Result_1'])\n",
    "\n",
    "df['Result_1'] = np.where(df['Result'] == 'ND', \"NO\", df['Result_1'])\n",
    "\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "## <span style=\"color:magenta\">DEALING with NULLS</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at rows with nan rest result\n",
    "\n",
    "df1 = df[df['Result'].isnull()]\n",
    "\n",
    "print(df1.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(df1[\"Facility_Description\"].unique())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of unique values that the code already deals with to check if there are new comments that requrie checking\n",
    "\n",
    "null_comments_deltWith = list(['This test is currently under evaluation and has not been fully validated.', \n",
    "                              'F',\n",
    "                               np.nan,\n",
    "                              'This assay is still undergoing development and is not yet fully~validated. Results should be interpreted in association with all other~information (clinical and laboratory) on the patient. Reports based on~this assay are not currently NATA/RCPA endorsed.~This test is currently under evaluation and has not been fully validated.',\n",
    "                              'Sample referred for confirmatory testing.~This test is currently under evaluation and has not been fully validated.',\n",
    "                              'Not Detected'])\n",
    "\n",
    "\n",
    "\n",
    "#STOP code if new comments have appeared\n",
    "if len(set(df1[\"Result_Comment\"].unique()) - set(null_comments_deltWith)) != 0:\n",
    "            print(\"ERROR: NEW NULL Comments!\\n\\n\",\n",
    "                  (set(df1[\"Result_Comment\"].unique()) - set(null_comments_deltWith)))\n",
    "            sys.exit()\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nulls with \"\"\n",
    "df1 = df1.replace(np.nan,\"\")\n",
    "\n",
    "\n",
    "#make results upper\n",
    "\n",
    "df1['Result_Comment'] = df1['Result_Comment'].str.upper()\n",
    "df1['Result'] = df1['Result'].str.upper()\n",
    "\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = list(df1[df1['Result_Comment'] == \"\"][\"Patient_ID\"])\n",
    "\n",
    "\n",
    "\n",
    "for i in patient:\n",
    "    print(i, \"had\", len(df1[df1['Patient_ID'] == i]), \"tests\")\n",
    "    \n",
    "    #display(df1[df1['Patient_ID'] == i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[\"Lab_No\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETECTED\n",
    "\n",
    "pattern1 = r\"REFERRED\"\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern1)]\n",
    "\n",
    "print(list(detected.Lab_No))\n",
    "\n",
    "display(detected.shape)\n",
    "\n",
    "detected.head()\n",
    "\n",
    "#replace values with YES in df\n",
    "for rows in detected.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"YES\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "\n",
    "#see whats left\n",
    "display(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "print(len(df[\"Lab_No\"].unique()))\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remaining are not detected\n",
    "for rows in df1.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"NO\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "\n",
    "df1 = df1[~df1.isin(df1)].dropna()\n",
    "\n",
    "#see whats left\n",
    "display(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "print(len(df[\"Lab_No\"].unique()))\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "\n",
    "## <span style=\"color:magenta\">DEALING with SEE COMMENTS</span>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df[\"Result\"]=='See Comment') | (df[\"Result\"]== 'See comment')]\n",
    "\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Nan with \"\"\n",
    "df1 = df1.replace(np.nan,\"\")\n",
    "\n",
    "df1['Result_Comment'] = df1['Result_Comment'].str.upper()\n",
    "\n",
    "\n",
    "len(df[\"Lab_No\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NULL values\n",
    "\n",
    "nulls = df1[df1.Result_Comment == \"\"]\n",
    "\n",
    "nulls.shape\n",
    "\n",
    "\n",
    "display(nulls.head())\n",
    "\n",
    "\n",
    "#replace values with NO in df\n",
    "for rows in nulls.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"NO\"   \n",
    "    \n",
    "#drop these from df1\n",
    "df1 = df1[~df1.isin(nulls)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT DETECTED\n",
    "#if the phrase 'not detected' is in the comments, change results_1 to NO\n",
    "\n",
    "pattern1 = r\"NOT\\sDETECTED\"\n",
    "\n",
    "not_detected = df1[df1.Result_Comment.str.contains(pattern1)]\n",
    "\n",
    "display(not_detected.shape)\n",
    "\n",
    "\n",
    "\n",
    "#replace values with NO in df\n",
    "for rows in not_detected.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"NO\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "df1 = df1[~df1.isin(not_detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETECTED\n",
    "#if the phrase 'detected' is in the comments, change results_1 to YES\n",
    "\n",
    "pattern2 = r\"DETECTED\"\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern2)]\n",
    "\n",
    "detected.shape\n",
    "\n",
    "detected.head()\n",
    "\n",
    "\n",
    "#replace values with NO in df\n",
    "for rows in detected.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"YES\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop those that have been \"combined\" with another test\n",
    "\n",
    "pattern3 = r\"COMBINED\\sWITH\\sLAB\"\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern3)]\n",
    "\n",
    "print(detected.shape)\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "\n",
    "print(len(df[\"Lab_No\"].unique()))\n",
    "\n",
    "#detected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop these from df\n",
    "df = df.drop(detected.index.values)\n",
    "\n",
    "#drop these from df1\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'This test has been performed on lab #...'\n",
    "#drop this weird value as it is a duplicate\n",
    "\n",
    "pattern4 = r'^THIS\\sTEST\\sHAS\\sBEEN\\sPERFORMED\\sON\\sLAB'\n",
    "\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern4)]\n",
    "\n",
    "#display(detected)\n",
    "\n",
    "#drop these from df\n",
    "df = df.drop(detected.index.values)\n",
    "\n",
    "#drop these from df1\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'UNABLE TO PERFORM NAA TEST #...'\n",
    "#drop this weird value as it a bung test\n",
    "\n",
    "pattern4 = r'^UNABLE\\sTO\\sPERFORM\\sNAA\\sTEST'\n",
    "\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern4)]\n",
    "\n",
    "display(detected)\n",
    "\n",
    "#drop these from df\n",
    "df = df.drop(detected.index.values)\n",
    "\n",
    "#drop these from df1\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "\n",
    "print(\"Number of patients :\", len(df[\"Patient_ID\"].unique()))\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests that have been referred are considered to have detected virus\n",
    "pattern2 = r\"REFERRED\"\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern2)]\n",
    "\n",
    "detected.shape\n",
    "\n",
    "detected.head()\n",
    "\n",
    "#replace values with YES in df\n",
    "for rows in detected.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"YES\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests that have been referred are considered to have detected virus\n",
    "pattern2 = r\"PROVISIONALLY\\sPOSITIVE\"\n",
    "\n",
    "detected = df1[df1.Result_Comment.str.contains(pattern2)]\n",
    "\n",
    "detected.shape\n",
    "\n",
    "#display(detected.head())\n",
    "\n",
    "#replace values with YES in df\n",
    "for rows in detected.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"YES\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "df1 = df1[~df1.isin(detected)].dropna()\n",
    "\n",
    "#see whats left\n",
    "print(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "print(len(df[\"Lab_No\"].unique()))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = list(df1[\"Patient_ID\"])\n",
    "\n",
    "\n",
    "for i in patient:\n",
    "    print(i, \"had\", len(df1[df1['Patient_ID'] == i]), \"tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remaining are not detected\n",
    "for rows in df1.index:\n",
    "    df.loc[df.index == rows, \"Result_1\"] = \"NO\"   \n",
    "    \n",
    "#drop these from df1\n",
    "\n",
    "\n",
    "df1 = df1[~df1.isin(df1)].dropna()\n",
    "\n",
    "#see whats left\n",
    "display(df1[\"Result_Comment\"].unique())\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP code if new comments have appeared\n",
    "if len(df1[\"Result_Comment\"].unique()) != 0:\n",
    "            print(\"ERROR: NEW NULL Comments!\\n\\n\",\n",
    "                  df1[\"Result_Comment\"].unique())\n",
    "            sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************\n",
    "\n",
    "# <span style=\"color:magenta\"> **STEP 4: REMOVE DUPLICATE LAB_NOs** <span>\n",
    "\n",
    "Same Lab_No but multiple test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df of duplicate Lab_No\n",
    "\n",
    "duplicates = df[df.duplicated(['Lab_No'], \n",
    "                              keep = False)].sort_values(['Lab_No'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')\n",
    "\n",
    "#replace Nan with \"\"\n",
    "duplicates = duplicates.replace(np.nan, '')\n",
    "\n",
    "df = df.replace(np.nan, '')\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop code if there are more than 3 results per Lab_No\n",
    "if duplicates.Lab_No.value_counts().max() > 4:\n",
    "    print(\"ERROR: More than 4 results per Lab_No\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "\n",
    "## <span style=\"color:magenta\">TWO DUPLICATES </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df with duplicates that only have two results per lab_no\n",
    "\n",
    "two_duplicates = duplicates[duplicates.groupby(\"Lab_No\")[\"Lab_No\"].transform('size') == 2][['Lab_No',\n",
    "                                                                                            \"Test_Code\",\n",
    "                                                                                            \"Result\",\n",
    "                                                                                            \"Result_Comment\",\n",
    "                                                                                            'Result_1']]\n",
    "print(two_duplicates.Test_Code.unique())\n",
    "\n",
    "print(len(two_duplicates))\n",
    "\n",
    "two_duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates that have the same result\n",
    "two_duplicates = two_duplicates.drop_duplicates(['Lab_No',\n",
    "                                                 'Result_1'])\n",
    "\n",
    "two_duplicates = two_duplicates.sort_values(by=['Lab_No',\n",
    "                                               \"Result_1\"])\n",
    "\n",
    "\n",
    "print(len(two_duplicates))\n",
    "\n",
    "two_duplicates.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get IDs of those who dont have duplicate values - these are the ones that have only 2 duplicates and the same result for both test\n",
    "IDs = two_duplicates[~two_duplicates.duplicated(['Lab_No'], keep = False)].sort_values(['Lab_No'],\n",
    "                                                                                       ascending= True,\n",
    "                                                                                       na_position='first')\n",
    "print(\"IDs\", IDs.shape)\n",
    "print(\"df before\", df.shape)\n",
    "\n",
    "#drop these from df\n",
    "df = df[~df.isin(IDs)].dropna()\n",
    "\n",
    "print(\"df after\", df.shape)\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get those with duplicate lab_no remaining - these are those with DIFFERENT lab results\n",
    "two_duplicates = two_duplicates[two_duplicates.duplicated(['Lab_No'], keep = False)].sort_values(['Lab_No'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')\n",
    "\n",
    "print(len(two_duplicates))\n",
    "\n",
    "two_duplicates.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests the code can deal with\n",
    "tests = ['CRTAQ', 'NCVPCR', 'CRPCR']\n",
    "\n",
    "\n",
    "\n",
    "#STOP code if new test codes have appeared\n",
    "if len(set(two_duplicates.Test_Code.unique()) - set(tests) ) != 0:\n",
    "    \n",
    "            print(\"ERROR: NEW TEST CODES!\\n\\n\",\n",
    "                  set(two_duplicates.Test_Code.unique()) - set(tests))\n",
    "        \n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = two_duplicates.pivot(index='Lab_No', columns='Test_Code', values=['Result_1',\n",
    "                                                                           \"Result\",\n",
    "                                                                           'Result_Comment'])\n",
    "\n",
    "#throw an error if there are any nulls in the CRTAQ column\n",
    "\n",
    "if len(nulls[nulls[\"Result_1\"][\"CRTAQ\"].isnull()]) > 0:\n",
    "    print(\"ERROR: Nulls in CRTAQ\")\n",
    "    sys.exit()\n",
    "\n",
    "    \n",
    "    \n",
    "two_duplicates.pivot(index='Lab_No', columns='Test_Code', values=['Result_1',\n",
    "                                                                  \"Result\",\n",
    "                                                                  'Result_Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of IDs to KEEP\n",
    "#IDs_keep\n",
    "\n",
    "#where either CRPCR is YES or CRTAQ is YES\n",
    "\n",
    "IDs = two_duplicates[(two_duplicates[\"Test_Code\"] == \"CRTAQ\") | (two_duplicates[\"Test_Code\"] == \"CRPCR\")]\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "#keep the yes values only if duplicate Lab_IDs\n",
    "\n",
    "#drop duplicates that have the same result\n",
    "IDs = IDs.drop_duplicates(['Lab_No',\n",
    "                           'Result_1'])\n",
    "\n",
    "#get the duplicates for CRPCR and CRTAQ with a different result\n",
    "IDs_duplicate = IDs[IDs.duplicated(['Lab_No'], \n",
    "                              keep = False)].sort_values(['Lab_No'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')\n",
    "\n",
    "#get the ones that say no\n",
    "IDs_duplicate = IDs_duplicate[IDs_duplicate.Result_1 == \"NO\"]\n",
    "\n",
    "#remove these from IDs\n",
    "IDs = IDs[~IDs.isin(IDs_duplicate)].dropna()\n",
    "\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "#save csv for validation\n",
    "IDs[[\"Lab_No\",\n",
    "    \"Result_1\"]].to_csv(\"Outputs/ForValidation/TwoLabNumbers.csv\")\n",
    "\n",
    "########################################\n",
    "\n",
    "#create df of IDs to REMOVE - drop two duplicates\n",
    "print(len(two_duplicates.Lab_No.unique()))\n",
    "\n",
    "IDs = two_duplicates[~two_duplicates.isin(IDs)].dropna()\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "#remove from df\n",
    "\n",
    "print(\"IDs\", IDs.shape)\n",
    "\n",
    "print(\"df before\", df.shape)\n",
    "\n",
    "#drop these from df\n",
    "df = df[~df.isin(IDs)].dropna()\n",
    "\n",
    "print(\"df after\", df.shape)\n",
    "\n",
    "len(df[\"Lab_No\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************\n",
    "\n",
    "### <span style=\"color:magenta\">THREE DUPLICATES</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df with duplicates that only have three results per lab_no\n",
    "\n",
    "thee_duplicates = duplicates[duplicates.groupby(\"Lab_No\")[\"Lab_No\"].transform('size') == 3][['Lab_No',\n",
    "                                                            \"Test_Code\",\n",
    "                                                            \"Result\",\n",
    "                                                            \"Result_Comment\",\n",
    "                                                            'Result_1']]\n",
    "\n",
    "print(len(thee_duplicates))\n",
    "display(thee_duplicates.head())\n",
    "\n",
    "\n",
    "display(thee_duplicates.pivot(index='Lab_No', columns='Test_Code', values=['Result_1',\n",
    "                                                                           \"Result\",\n",
    "                                                                           'Result_Comment']).head(15))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tests the code can deal with\n",
    "tests = ['CRTAQ', 'NCVPCR', 'CRPCR']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "nulls = thee_duplicates.pivot(index='Lab_No', columns='Test_Code', values=['Result_1',\n",
    "                                                                           \"Result\",\n",
    "                                                                           'Result_Comment'])\n",
    "\n",
    "#throw an error if there are any nulls in the CRTAQ column\n",
    "\n",
    "if len(nulls[nulls[\"Result_1\"][\"CRTAQ\"].isnull()]) > 0:\n",
    "    print(\"ERROR: Nulls in CRTAQ\")\n",
    "    sys.exit()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of IDs to KEEP\n",
    "#IDs_keep\n",
    "\n",
    "#where either CRPCR is YES or CRTAQ is YES\n",
    "\n",
    "IDs = thee_duplicates[(thee_duplicates[\"Test_Code\"] == \"CRTAQ\") | (thee_duplicates[\"Test_Code\"] == \"CRPCR\")]\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "#drop duplicates that have the same result\n",
    "IDs = IDs.drop_duplicates(['Lab_No',\n",
    "                           'Result_1'])\n",
    "\n",
    "\n",
    "#get the duplicates for CRPCR and CRTAQ with a different result\n",
    "IDs_duplicate = IDs[IDs.duplicated(['Lab_No'], \n",
    "                              keep = False)].sort_values(['Lab_No'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')\n",
    "\n",
    "#get the ones that say no\n",
    "IDs_duplicate = IDs_duplicate[IDs_duplicate.Result_1 == \"NO\"]\n",
    "\n",
    "#remove these from IDs\n",
    "IDs = IDs[~IDs.isin(IDs_duplicate)].dropna()\n",
    "\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "display(IDs[[\"Lab_No\",\n",
    "    \"Result_1\"]])\n",
    "\n",
    "#save csv for validation\n",
    "IDs[[\"Lab_No\",\n",
    "    \"Result_1\"]].to_csv(\"Outputs/ForValidation/ThreeLabNumbers.csv\")\n",
    "\n",
    "########################################\n",
    "\n",
    "#create df of IDs to REMOVE - drop two duplicates\n",
    "print(len(thee_duplicates.Lab_No.unique()))\n",
    "\n",
    "IDs = thee_duplicates[~thee_duplicates.isin(IDs)].dropna()\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "#remove from df\n",
    "\n",
    "print(\"IDs\", IDs.shape)\n",
    "\n",
    "print(\"df before\", df.shape)\n",
    "\n",
    "#drop these from df\n",
    "df = df[~df.isin(IDs)].dropna()\n",
    "\n",
    "print(\"df after\", df.shape)\n",
    "\n",
    "len(df[\"Lab_No\"].unique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************\n",
    "\n",
    "\n",
    "### <span style=\"color:magenta\">FOUR DUPLICATES</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df with duplicates that only have three results per lab_no\n",
    "\n",
    "four_duplicates = duplicates[duplicates.groupby(\"Lab_No\")[\"Lab_No\"].transform('size') == 4][['Lab_No',\n",
    "                                                            \"Test_Code\",\n",
    "                                                            \"Result\",\n",
    "                                                            \"Result_Comment\",\n",
    "                                                            'Result_1']]\n",
    "\n",
    "print(len(four_duplicates))\n",
    "display(four_duplicates.head())\n",
    "\n",
    "\n",
    "display(four_duplicates.pivot(index='Lab_No', columns='Test_Code', values=['Result_1',\n",
    "                                                                           \"Result\",\n",
    "                                                                           'Result_Comment']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = four_duplicates.pivot(index='Lab_No', columns='Test_Code', values=['Result_1',\n",
    "                                                                           \"Result\",\n",
    "                                                                           'Result_Comment'])\n",
    "\n",
    "#throw an error if there are any nulls in the CRTAQ column\n",
    "\n",
    "if len(nulls[nulls[\"Result_1\"][\"CRTAQ\"].isnull()]) > 0:\n",
    "    print(\"ERROR: Nulls in CRTAQ\")\n",
    "    sys.exit()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of IDs to KEEP\n",
    "#IDs_keep\n",
    "\n",
    "#where either CRPCR is YES or CRTAQ is YES\n",
    "\n",
    "IDs = four_duplicates[(four_duplicates[\"Test_Code\"] == \"CRTAQ\") | (four_duplicates[\"Test_Code\"] == \"CRPCR\")]\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "#drop duplicates that have the same result\n",
    "IDs = IDs.drop_duplicates(['Lab_No',\n",
    "                           'Result_1'])\n",
    "\n",
    "\n",
    "#get the duplicates for CRPCR and CRTAQ with a different result\n",
    "IDs_duplicate = IDs[IDs.duplicated(['Lab_No'], \n",
    "                              keep = False)].sort_values(['Lab_No'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')\n",
    "\n",
    "#get the ones that say no\n",
    "IDs_duplicate = IDs_duplicate[IDs_duplicate.Result_1 == \"NO\"]\n",
    "\n",
    "#remove these from IDs\n",
    "IDs = IDs[~IDs.isin(IDs_duplicate)].dropna()\n",
    "\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "#save csv for validation\n",
    "IDs[[\"Lab_No\",\n",
    "    \"Result_1\"]].to_csv(\"Outputs/ForValidation/FourLabNumbers.csv\")\n",
    "\n",
    "########################################\n",
    "\n",
    "#create df of IDs to REMOVE - drop two duplicates\n",
    "print(len(four_duplicates.Lab_No.unique()))\n",
    "\n",
    "IDs = four_duplicates[~four_duplicates.isin(IDs)].dropna()\n",
    "\n",
    "print(len(IDs.Lab_No.unique()))\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "#remove from df\n",
    "\n",
    "print(\"IDs\", IDs.shape)\n",
    "\n",
    "print(\"df before\", df.shape)\n",
    "\n",
    "#drop these from df\n",
    "df = df[~df.isin(IDs)].dropna()\n",
    "\n",
    "print(\"df after\", df.shape)\n",
    "\n",
    "len(df[\"Lab_No\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that duplicates have been removed\n",
    "first_dedup_length = len(df)\n",
    "\n",
    "print(\"Number of rows: \", first_dedup_length)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Number of tests: \", len(df.Lab_No.unique()))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "if len(df) != len(df.Lab_No.unique()):\n",
    "    \n",
    "    print(\"Duplicates not removed!!!!\")\n",
    "    sys.exit()\n",
    "    \n",
    "else:\n",
    "    print(\"All duplicates removed\")\n",
    "                   \n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Lab_No with manually varified results\n",
    "Lab_Nos are manually varified by clinician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Lab_No result with manually varified result\n",
    "\n",
    "#If result = DETECTED then RESULT_1 is YES, otherwise put NO\n",
    "df_manual['Result_1'] = np.where(df_manual['ClinicianDeterminedResult'] == 'D', \"YES\", \"NO\")\n",
    "\n",
    "#reset the index to ID\n",
    "df_manual = df_manual.set_index('ID')\n",
    "\n",
    "df_manual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name the index of df\n",
    "df.index.name = 'ID'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace values\n",
    "df.loc[df.Lab_No.isin(df_manual.Lab_No), ['Result_1']] = df_manual[['Result_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save lab tests\n",
    "df[['Patient_ID',\n",
    "    'Lab_No', \n",
    "    'Date_Collected',\n",
    "    'Time_collected',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    \"Result_1\",\n",
    "    'DateTime_Collected',\n",
    "    'Area']].to_csv(\"Outputs/WrangledData/tests_area.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:magenta\"> **STEP 5: REMOVE DUPLUCATE RESULTS ON THE SAME DAY** </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['DateTime_Collected'],\n",
    "               ascending= True,\n",
    "               na_position='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of tests taken at the same time on the same day with the same result\n",
    "\n",
    "removed = len(df[df.duplicated([#'Lab_No', \n",
    "                  #'Test_Code', \n",
    "                  #'Test_Description',\n",
    "                  'Date_Collected',\n",
    "                  #'Time_collected',\n",
    "                  #'UrNo', \n",
    "                  #'Surname', \n",
    "                  #'First_Names', \n",
    "                  #'Date_of_Birth',\n",
    "                  #'Sex', \n",
    "                  #'Age', \n",
    "                  #'Category_Code', \n",
    "                  #'Facility_Code', \n",
    "                  #'Facility_Description',\n",
    "                  #'Result', \n",
    "                  #'Result_Comment', \n",
    "                  #'DateTime_Collected',\n",
    "                  'Result_1',\n",
    "    'Patient_ID'])])\n",
    "              \n",
    "removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates that have the same result for different tests on the same time/day\n",
    "\n",
    "df = df.drop_duplicates([#'Lab_No', \n",
    "                  #'Test_Code', \n",
    "                  #'Test_Description',\n",
    "                  'Date_Collected',\n",
    "                  #'Time_collected',\n",
    "                  #'UrNo', \n",
    "                  #'Surname', \n",
    "                  #'First_Names', \n",
    "                  #'Date_of_Birth',\n",
    "                  #'Sex', \n",
    "                  #'Age', \n",
    "                  #'Category_Code', \n",
    "                  #'Facility_Code', \n",
    "                  #'Facility_Description',\n",
    "                  #'Result', \n",
    "                  #'Result_Comment', \n",
    "                  #'DateTime_Collected',\n",
    "                  'Result_1',\n",
    "                  'Patient_ID'])\n",
    "\n",
    "df = df.sort_values(by=['Lab_No',\n",
    "                        \"Result_1\"])\n",
    "\n",
    "\n",
    "print(len(df[df.duplicated([#'Lab_No', \n",
    "                  #'Test_Code', \n",
    "                  #'Test_Description',\n",
    "                  'Date_Collected',\n",
    "                  #'Time_collected',\n",
    "                  #'UrNo', \n",
    "                  #'Surname', \n",
    "                  #'First_Names', \n",
    "                  #'Date_of_Birth',\n",
    "                  #'Sex', \n",
    "                  #'Age', \n",
    "                  #'Category_Code', \n",
    "                  #'Facility_Code', \n",
    "                  #'Facility_Description',\n",
    "                  #'Result', \n",
    "                  #'Result_Comment', \n",
    "                  #'DateTime_Collected',\n",
    "                  'Result_1',\n",
    "                  'Patient_ID'], keep = False)].sort_values(['Patient_ID'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')))\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that duplicates have been removed\n",
    "second_dedup_length = len(df)\n",
    "\n",
    "print(\"Number of rows: \", second_dedup_length)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Should be: \", first_dedup_length - removed)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "if first_dedup_length - removed != second_dedup_length:\n",
    "    \n",
    "    print(\"Duplicates not removed!!!!\")\n",
    "    sys.exit()\n",
    "    \n",
    "else:\n",
    "    print(\"All duplicates removed\")\n",
    "                   \n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Unique patients: \", len(df.Patient_ID.unique()))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Unique tests: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to keep \"YES\" for days with YES and NO results on the same day\n",
    "\n",
    "#get rows that more than one test for the patien on the same day\n",
    "duplicates = df[df.duplicated([#'Lab_No', \n",
    "                  #'Test_Code', \n",
    "                  #'Test_Description',\n",
    "                  'Date_Collected',\n",
    "                  #'Time_collected',\n",
    "                  #'UrNo', \n",
    "                  #'Surname', \n",
    "                  #'First_Names', \n",
    "                  #'Date_of_Birth',\n",
    "                  #'Sex', \n",
    "                  #'Age', \n",
    "                  #'Category_Code', \n",
    "                  #'Facility_Code', \n",
    "                  #'Facility_Description',\n",
    "                  #'Result', \n",
    "                  #'Result_Comment', \n",
    "                  #'DateTime_Collected',\n",
    "                  #'Result_1',\n",
    "                  'Patient_ID'], keep = False)].sort_values(['Patient_ID'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first')\n",
    "\n",
    "\n",
    "display(duplicates.head())\n",
    "\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get values where Result_1 is NO\n",
    "IDs = duplicates[duplicates[\"Result_1\"]== \"NO\"]\n",
    "\n",
    "print(\"IDs\", IDs.shape)\n",
    "\n",
    "print(\"df before\", df.shape)\n",
    "\n",
    "#drop these from df\n",
    "df = df[~df.isin(IDs)].dropna()\n",
    "\n",
    "print(\"df after\", df.shape)\n",
    "\n",
    "len(df[\"Lab_No\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that it worked\n",
    "display(df[df.duplicated([#'Lab_No', \n",
    "                  #'Test_Code', \n",
    "                  #'Test_Description',\n",
    "                  'Date_Collected',\n",
    "                  #'Time_collected',\n",
    "                  #'UrNo', \n",
    "                  #'Surname', \n",
    "                  #'First_Names', \n",
    "                  #'Date_of_Birth',\n",
    "                  #'Sex', \n",
    "                  #'Age', \n",
    "                  #'Category_Code', \n",
    "                  #'Facility_Code', \n",
    "                  #'Facility_Description',\n",
    "                  #'Result', \n",
    "                  #'Result_Comment', \n",
    "                  #'DateTime_Collected',\n",
    "                  #'Result_1',\n",
    "                  'Patient_ID'], keep = False)].sort_values(['Patient_ID'],\n",
    "                                                        ascending= True,\n",
    "                                                        na_position='first'))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Unique Lab_No/tests: \", len(df.Lab_No.unique()))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Rows in df: \", len(df))\n",
    "\n",
    "print(\"Patients df: \", len(df.Patient_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save lab tests\n",
    "df[['Patient_ID',\n",
    "    'Lab_No', \n",
    "    'Date_Collected',\n",
    "    'Time_collected',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    \"Result_1\",\n",
    "    'DateTime_Collected',\n",
    "    'Area']].to_csv(\"Outputs/WrangledData/all_data_preCalcs.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************\n",
    "\n",
    "# <span style=\"color:magenta\"> **STEP 6: CREATE FINAL DATAFRAME**<span>\n",
    "\n",
    "Drop unneeded columns and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[[\"Patient_ID\",\n",
    "               \"Age\",\n",
    "               'Sex',\n",
    "               'Date_Collected',\n",
    "               'Time_collected',\n",
    "               'DateTime_Collected',\n",
    "               'Result_1',\n",
    "               'Facility_Description',\n",
    "              'AgeGroup',\n",
    "               'PostCode',\n",
    "               'Area']]\n",
    "\n",
    "print(df_final.dtypes)\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final[\"DateTime_Collected\"] = pd.to_datetime(df_final[\"DateTime_Collected\"], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "#df_final[\"Date_Collected\"] = pd.to_datetime(df_final[\"Date_Collected\"], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "#create column to add days since first test\n",
    "df_final[\"DaySinceFirstTest\"] = np.nan\n",
    "\n",
    "#create column to add days since first POSITIVE test\n",
    "df_final[\"DaySinceFirstPOSITIVETest\"] = np.nan\n",
    "\n",
    "#number of tests\n",
    "df_final[\"NumberOfTests\"] = np.nan\n",
    "\n",
    "#number of tests since first positive\n",
    "df_final[\"NumberOfTestsSinceFirstPOSITIVE\"] = np.nan\n",
    "\n",
    "#number of tests before first positive\n",
    "df_final[\"NumberOfTestsBeforeFirstPOSITIVE\"] = np.nan\n",
    "\n",
    "\n",
    "#number of negative tests\n",
    "df_final[\"NumberOfNegTests\"] = np.nan\n",
    "\n",
    "#number of positive tests\n",
    "df_final[\"NumberOfPosTests\"] = np.nan\n",
    "\n",
    "\n",
    "# days since and including first poisitive test - this will be used to order visual\n",
    "df_final[\"MaxDayTestSinceFirstPOSITIVETest\"] = np.nan\n",
    "\n",
    "# days test before first poisitive - this will be used to order visual\n",
    "df_final[\"MaxDayTestBEFOREFirstPOSITIVETest\"] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#days to negative status - for filtering\n",
    "df_final[\"DaysToNegStatus\"] = np.nan\n",
    "\n",
    "#days to negative status when first negative status is ignored - for filtering\n",
    "df_final[\"DaysToNegStatus_sensitiv\"] = np.nan\n",
    "\n",
    "\n",
    "#days to biological negative status\n",
    "df_final[\"DaysToNegStatus_biol\"] = np.nan\n",
    "\n",
    "#days to negative status when first negative status is ignored\n",
    "df_final[\"DaysToNegStatus_sensitiv_biol\"] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "#days to biological negative status OR final neg test\n",
    "df_final[\"DaysToNegStatus_sensitivCensored\"] = np.nan\n",
    "\n",
    "#days to biological negative status OR final neg test when first negative status is ignored\n",
    "df_final[\"DaysToNegStatus_sensitivUNCensored\"] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#number of result changes until first positive to DaysToNegStatus_biol\n",
    "df_final[\"ResultChangeToNegStatus\"] = np.nan\n",
    "\n",
    "#number of result changes to DaysToNegStatus_sensitiv_biol\n",
    "df_final[\"ResultChangeToFinalNegStatus\"] = np.nan\n",
    "\n",
    "\n",
    "# STATUS COLUMN\n",
    "df_final[\"Status\"]  = \"NEG\"\n",
    "\n",
    "\n",
    "#column to indicate a status change from neg to pos and pos to neg\n",
    "df_final[\"Status_Change\"]  = np.nan\n",
    "\n",
    "#Area for the first test\n",
    "df_final[\"AreaFirstTest\"]  = np.nan\n",
    "df_final[\"PostCodeFirstTest\"]  = np.nan\n",
    "df_final[\"FacilityFirstTest\"]  = np.nan\n",
    "\n",
    "\n",
    "\n",
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.Patient_ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of patients\n",
    "patient_list = df_final[\"Patient_ID\"].unique()\n",
    "\n",
    "\n",
    "for patient in patient_list:  \n",
    "    \n",
    "    \n",
    "    df1 = df_final[df_final[\"Patient_ID\"] == patient].sort_values(by = 'DateTime_Collected') #for each patient get their tests and sort according to datet_time\n",
    "    \n",
    "    \n",
    "    ######################################### DAYS SINCE 'n' TEST\n",
    "\n",
    "    #calcualte the date of first test\n",
    "    first_date = df1[\"Date_Collected\"].min()\n",
    "\n",
    "    #get first instance of a POSITIVE result\n",
    "\n",
    "    idx = (df1['Result_1'] >= \"YES\").idxmax()\n",
    "\n",
    "\n",
    "    first_date_pos = df1.loc[idx, \"Date_Collected\"]\n",
    "\n",
    "\n",
    "\n",
    "    #number of days since first test \n",
    "    df1[\"DaySinceFirstTest\"] = (df1[\"Date_Collected\"] - first_date)/ np.timedelta64(1, 'D')\n",
    "\n",
    "    #number of days since first POSITIVE test    \n",
    "    df1[\"DaySinceFirstPOSITIVETest\"] = (df1[\"Date_Collected\"] - first_date_pos)/ np.timedelta64(1, 'D')\n",
    "\n",
    "\n",
    "\n",
    "    ######################################### DEFINE PATIENT STATUS\n",
    "\n",
    "    #Define a new column for the previous day's results and copy results\n",
    "    Result_Prev = df1[\"Result_1\"]\n",
    "\n",
    "\n",
    "    #Shift the results data down by one\n",
    "    Result_Prev = Result_Prev.shift(periods=1)\n",
    "\n",
    "\n",
    "    #Insert new results column into data frame\n",
    "    df1.insert(7, 'Result_Prev', Result_Prev)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Define a new column for the previous day's result time and copy results\n",
    "    DateTime_Collected_Prev = df1[\"DateTime_Collected\"]\n",
    "\n",
    "\n",
    "    #Shift the results data down by one\n",
    "    DateTime_Collected_Prev = DateTime_Collected_Prev.shift(periods=1)\n",
    "\n",
    "\n",
    "    #Insert new results column into data frame\n",
    "    df1.insert(6, 'DateTime_Collected_Prev', DateTime_Collected_Prev)\n",
    "\n",
    "    df1[\"TimeDifference\"] = (df1[\"DateTime_Collected\"] - df1['DateTime_Collected_Prev']).astype('timedelta64[h]')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Calculate status\n",
    "    df1.loc[(df1['Result_Prev'].isnull()) & (df1['Result_1'] == \"YES\"), 'Status'] = \"POS\"\n",
    "\n",
    "    df1.loc[(df1['Result_Prev'] == \"YES\") | (df1['Result_1'] == \"YES\"), 'Status'] = \"POS\"\n",
    "\n",
    "    df1.loc[(df1['Result_Prev'] == \"NO\") & (df1['Result_1'] == \"NO\") & (df1[\"TimeDifference\"] >= 24), 'Status'] = \"NEG\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###################################### DEFINE NEGATIVE STATUS OCCURANCES\n",
    "\n",
    "\n",
    "    #Define a new column for the previous day's results and copy results\n",
    "    Status_Prev = df1[\"Status\"]\n",
    "\n",
    "\n",
    "    #Shift the results data down by one\n",
    "    Status_Prev = Status_Prev.shift(periods=1)\n",
    "\n",
    "\n",
    "    #Insert new results column into data frame\n",
    "    df1.insert(16, 'Status_Prev', Status_Prev)\n",
    "\n",
    "\n",
    "    #Calculate status change from POS to NEG\n",
    "    df1.loc[(df1['Status_Prev'] == \"POS\") & (df1['Status'] == \"NEG\") & (df1['DaySinceFirstPOSITIVETest'] != 0), 'Status_Change'] = 1\n",
    "\n",
    "\n",
    "    #Calculate status change from NEG to POS after initial positive\n",
    "    df1.loc[(df1['Status_Prev'] == \"NEG\") & (df1['Status'] == \"POS\") & (df1['DaySinceFirstPOSITIVETest'] != 0), 'Status_Change'] = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######################################### REMOVE MULTIPLE NEGATIVE RESULTS AT END (REDUNDANT RESULTS)\n",
    "\n",
    "    #get a list of row numbers the reverse the order\n",
    "    rows = list(range(0, len(df1)))[::-1]\n",
    "\n",
    "    #get the column numner for status\n",
    "    columnStatus = df1.columns.get_loc(\"Status\")\n",
    "\n",
    "    #get the column numner for previous status\n",
    "    columnStatusPrev = df1.columns.get_loc(\"Status_Prev\")\n",
    "\n",
    "    #loop through in reverse\n",
    "    for i in rows:\n",
    "\n",
    "        #if the last two status are NEG then remove the row\n",
    "        if ((df1.iloc[i, columnStatus] == \"NEG\") & (df1.iloc[i, columnStatusPrev] == \"NEG\")):\n",
    "            df1 = df1.iloc[:-1,]\n",
    "\n",
    "        #otherwise get out of the loop\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    ###################################### DEFINE TIME TO FIRST NEGATIVE STATUS: BIOLOGICAL AND CLINICAL\n",
    "\n",
    "\n",
    "    #Define a new column for the previous number of days since first positive and copy results\n",
    "    DaysSinceFirstPos_Prev = df1[\"DaySinceFirstPOSITIVETest\"]\n",
    "\n",
    "\n",
    "    #Shift the results data down by one\n",
    "    DaysSinceFirstPos_Prev = DaysSinceFirstPos_Prev.shift(periods=1)\n",
    "\n",
    "    #Insert new results column into data frame\n",
    "    df1.insert(16, 'DaysSinceFirstPos_Prev', DaysSinceFirstPos_Prev)\n",
    "\n",
    "    #column number for days since first pos - previous test result for BIOLOGICALLY neg status \n",
    "    daysPrev = df1.columns.get_loc(\"DaysSinceFirstPos_Prev\")\n",
    "\n",
    "\n",
    "\n",
    "    #if a negative status is achieved at some point\n",
    "    if (len(df1[df1[\"Status_Change\"] == 1]) > 0) :\n",
    "\n",
    "        #BIOLOGICAL time to negative is the FIRST occurance of the change to negative status\n",
    "        df1[\"DaysToNegStatus_biol\"] = df1[df1[\"Status_Change\"] == 1].iloc[0,daysPrev]\n",
    "\n",
    "        #BIOLOGICAL time to negative is the LAST data row\n",
    "        df1[\"DaysToNegStatus_sensitiv_biol\"] = df1[\"DaySinceFirstPOSITIVETest\"].max() #if last status is pos\n",
    "\n",
    "        #print(df1[\"DaySinceFirstPOSITIVETest\"].max())\n",
    "\n",
    "        #display(df1[\"DaySinceFirstPOSITIVETest\"])\n",
    "\n",
    "        #CLINICAL time to negative is the FIRST occurance of the change to negative status\n",
    "        df1[\"DaysToNegStatus\"] = df1.loc[(df1['Status_Change'] == 1.0).idxmax(), \"DaySinceFirstPOSITIVETest\"]\n",
    "\n",
    "        #CLINICAL time to negative is the LAST data row\n",
    "        df1[\"DaysToNegStatus_sensitiv\"] = df1[\"DaySinceFirstPOSITIVETest\"].max()\n",
    "\n",
    "\n",
    "\n",
    "    if (len(df1[df1[\"Status_Change\"] == 1]) > 0 ) & (df1.iloc[-1,df1.columns.get_loc(\"Status\")]  == \"NEG\"):\n",
    "\n",
    "        df1[\"DaysToNegStatus_sensitiv_biol\"] = df1.iloc[len(df1)-1,df1.columns.get_loc(\"DaysSinceFirstPos_Prev\")]  #if the last status is neg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #if a negative status is never achieved in a previously positive patient   \n",
    "    if (len(df1[df1[\"Status_Change\"] == 1]) == 0) & (df1[df1[\"DaySinceFirstPOSITIVETest\"] == 0][\"Status\"].item() == \"POS\"):\n",
    "\n",
    "        df1[\"DaysToNegStatus_biol\"] = df1[\"DaySinceFirstPOSITIVETest\"].max()\n",
    "\n",
    "        df1[\"DaysToNegStatus_sensitiv_biol\"] = df1[\"DaySinceFirstPOSITIVETest\"].max()\n",
    "\n",
    "        df1[\"DaysToNegStatus\"] = df1[\"DaySinceFirstPOSITIVETest\"].max()\n",
    "\n",
    "        df1[\"DaysToNegStatus_sensitiv\"] = df1[\"DaySinceFirstPOSITIVETest\"].max()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###################################### DEFINE TIME TO FIRST NEGATIVE STATUS: BIOLOGICAL OR FINAL NEG TEST   \n",
    "\n",
    "     #check to see that days to neg is not null\n",
    "    if pd.notnull(df1.DaysToNegStatus.iloc[0]):\n",
    "\n",
    "        #days to biological negative status OR final neg test\n",
    "        days = df1.DaysToNegStatus.iloc[0]\n",
    "\n",
    "        days_negAch = df1.DaysToNegStatus_biol.iloc[0]\n",
    "\n",
    "        #if negative status - then use days to neg status\n",
    "        if (df1[(df1.DaySinceFirstPOSITIVETest == days)].Status == \"NEG\").item():\n",
    "            df1[\"DaysToNegStatus_sensitivCensored\"] = days_negAch\n",
    "\n",
    "        #if postivive status BUT last test neg\n",
    "        if (((df1[(df1.DaySinceFirstPOSITIVETest == days)].Status == \"POS\") & (df1[(df1.DaySinceFirstPOSITIVETest == days)].Result_1 == \"NO\"))).item():\n",
    "\n",
    "            df1[\"DaysToNegStatus_sensitivCensored\"] = days\n",
    "\n",
    "\n",
    "\n",
    "        #days to biological negative status OR final neg test when first negative status is ignored\n",
    "        days = df1.DaysToNegStatus_sensitiv.iloc[0]\n",
    "\n",
    "        days_negAch = df1.DaysToNegStatus_sensitiv_biol.iloc[0]\n",
    "\n",
    "        #if negative status - then use days to neg status\n",
    "        if (df1[(df1.DaySinceFirstPOSITIVETest == days)].Status == \"NEG\").item():\n",
    "            df1[\"DaysToNegStatus_sensitivUNCensored\"] = days_negAch\n",
    "\n",
    "        #if postivive status BUT last test neg\n",
    "        if (((df1[(df1.DaySinceFirstPOSITIVETest == days)].Status == \"POS\") & (df1[(df1.DaySinceFirstPOSITIVETest == days)].Result_1 == \"NO\"))).item():\n",
    "\n",
    "            df1[\"DaysToNegStatus_sensitivUNCensored\"] = days\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######################################### MAX and MIN DAYS SINCE 'n' TEST\n",
    "\n",
    "\n",
    "    #MAX days after first positive test\n",
    "    df1[\"MaxDayTestSinceFirstPOSITIVETest\"] = df1[\"DaySinceFirstPOSITIVETest\"].max()\n",
    "\n",
    "\n",
    "    #MAX days before first positive test\n",
    "    df1[\"MaxDayTestBEFOREFirstPOSITIVETest\"] = df1[\"DaySinceFirstPOSITIVETest\"].min()\n",
    "\n",
    "\n",
    "\n",
    "    #number of tests done after and including first positive\n",
    "    df1[\"NumberOfTestsSinceFirstPOSITIVE\"] = len(df1[(df1[\"DaySinceFirstPOSITIVETest\"] >=0)])\n",
    "\n",
    "    #number of tests done befre and excluding first positive\n",
    "    df1[\"NumberOfTestsBeforeFirstPOSITIVE\"] = len(df1[df1[\"DaySinceFirstPOSITIVETest\"] < 0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################### COUNT THE NUMBER OF CHANGES IN RESULTS FROM POS TO NEG\n",
    "\n",
    "\n",
    "\n",
    "    #number of result changes until first positive\n",
    "    df1[\"ResultChangeToNegStatus\"] = len(df1[(df1[\"Result_1\"] == \"YES\") & (df1[\"Result_Prev\"] == \"NO\") & (df1[\"DaySinceFirstPOSITIVETest\"] <=df1['DaysToNegStatus'])])\n",
    "\n",
    "    #number of result changes until final positive\n",
    "    df1[\"ResultChangeToFinalNegStatus\"] = len(df1[(df1[\"Result_1\"] == \"YES\") & (df1[\"Result_Prev\"] == \"NO\")])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######################################### NUMBER OF TESTS\n",
    "\n",
    "    #TOTAL number of tests\n",
    "    df1[\"NumberOfTests\"] = len(df1)\n",
    "\n",
    "\n",
    "    # number of negative tests  \n",
    "    df1[\"NumberOfNegTests\"] = len(df1[(df1[\"Result_1\"] == \"NO\") & (df1[\"DaySinceFirstPOSITIVETest\"] >=0)])\n",
    "\n",
    "    #number of positive tests\n",
    "\n",
    "    df1[\"NumberOfPosTests\"] = len(df1[(df1[\"Result_1\"] == \"YES\") & (df1[\"DaySinceFirstPOSITIVETest\"] >= 0)])\n",
    "\n",
    "\n",
    "\n",
    "    ########################### AREA OF FIRST TEST \n",
    "\n",
    "    df1[\"AreaFirstTest\"]  =  df1.iloc[0, df1.columns.get_loc(\"Area\")]\n",
    "    df1[\"PostCodeFirstTest\"]  = df1.iloc[0, df1.columns.get_loc('PostCode')]\n",
    "    df1[\"FacilityFirstTest\"]  = df1.iloc[0, df1.columns.get_loc('Facility_Description')]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df_final.update(df1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1 = df_final.copy()\n",
    "\n",
    "display(df_final1)\n",
    "\n",
    "df_final1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the values \n",
    "df_final1 = df_final1[df_final1['DaySinceFirstTest'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1[\"NumberOfTestsSinceFirstPOSITIVE\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1[\"DaySinceFirstTest\"] = df_final1[\"DaySinceFirstTest\"].astype(int)\n",
    "df_final1[\"DaySinceFirstPOSITIVETest\"] = df_final1[\"DaySinceFirstPOSITIVETest\"].astype(int)\n",
    "df_final1[\"MaxDayTestSinceFirstPOSITIVETest\"] = df_final1[\"MaxDayTestSinceFirstPOSITIVETest\"].astype(int)\n",
    "df_final1[\"Patient_ID\"] = df_final1[\"Patient_ID\"].astype(int)\n",
    "df_final1[\"Age\"] = df_final1[\"Age\"].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_final1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that there are no groups with < 5 patients\n",
    "df_final1.AgeGroup.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file\n",
    "df_final1.to_csv(\"Outputs/WrangledData/all_results.csv\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
